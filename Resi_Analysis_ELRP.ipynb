{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4412ae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0_/q6d4fymj0v9bl3m8gdcnl6n40000gn/T/ipykernel_40781/1883485394.py:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime as dt\n"
     ]
    }
   ],
   "source": [
    "#Import statements\n",
    "import pandas as pd\n",
    "from pandas import datetime as dt\n",
    "import csv\n",
    "import numpy as np\n",
    "#import lib.google_sheet_api as gs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5cd569",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/suneetakartha/Downloads/Med Consumption.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8d9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data\n",
    "\n",
    "# site_interval_data = pd.read_csv(filename)\n",
    "site_interval_data.columns = ['date', 'month', 'day', 'hour', 'load_net_solar', 'solar', 'battery','gross_load','soc_real','soc_sterile_2hr','soc_sterile_4hr']\n",
    "\n",
    "\n",
    "site_interval_data['date']=pd.to_datetime(site_interval_data['date'], utc=True)\n",
    "site_interval_data['solar']=site_interval_data['solar'].fillna(0)\n",
    "\n",
    "site_interval_data['week'] = site_interval_data['date'] - pd.offsets.Week(weekday=6)\n",
    "site_interval_data['dow']= site_interval_data['date'].dt.dayofweek\n",
    "site_interval_data['month']= site_interval_data['date'].dt.month\n",
    "\n",
    "d=({'load_net_solar':'load_net_solar.sum', 'solar':'solar.sum', 'battery':'battery.sum','gross_load':'gross_load.sum'\n",
    "                    ,'soc_real':'soc_real.avg','soc_sterile_2hr':'soc_sterile_2hr.avg','soc_sterile_4hr':'soc_sterile_4hr.avg'})\n",
    "site_interval_data=(site_interval_data.groupby(['date','month', 'hour'])\n",
    "                    .agg({'load_net_solar':'sum', 'solar':'sum', 'battery':'sum','gross_load':'sum'\n",
    "                          ,'soc_real':'mean','soc_sterile_2hr':'mean','soc_sterile_4hr':'mean'})).reset_index()\n",
    "# site_interval_data['SOC_net']= site_interval_data.groupby(['date'])['solar'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d18c77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('~/Downloads/ELRP_sample_data.xlsx')\n",
    "site_interval_data1 = pd.read_excel(xls, 'Battery Scenario 1.1.A')\n",
    "site_interval_data2 = pd.read_excel(xls, 'Battery Scenario 1.2.A')\n",
    "site_interval_data3 = pd.read_excel(xls, 'Battery Scenario 1.3.A')\n",
    "site_interval_data4 = pd.read_excel(xls, 'Battery Scenario 2.1.A')\n",
    "site_interval_data5 = pd.read_excel(xls, 'Battery Scenario 2.2.A')\n",
    "site_interval_data6 = pd.read_excel(xls, 'Battery Scenario 2.3.A')\n",
    "\n",
    "def clean_data(site_interval_data):\n",
    "    site_interval_data.columns = ['date', 'hour', 'month', 'gross_load', 'battery', 'battery_2_hr', 'battery_4_hr']\n",
    "\n",
    "\n",
    "    site_interval_data['date']=pd.to_datetime(site_interval_data['date'], utc=True)\n",
    "\n",
    "    site_interval_data['week'] = site_interval_data['date'] - pd.offsets.Week(weekday=6)\n",
    "    site_interval_data['dow']= site_interval_data['date'].dt.dayofweek\n",
    "    site_interval_data['month']= site_interval_data['date'].dt.month\n",
    "\n",
    "    d=({'gross_load':'gross_load.sum', 'battery':'battery.sum','battery_2_hr':'battery_2_hr.sum'\n",
    "                        ,'battery_4_hr':'battery_4_hr.avg'})\n",
    "    site_interval_data=(site_interval_data.groupby(['date','month', 'hour'])\n",
    "                        .agg({'gross_load':'sum', 'battery':'sum', \n",
    "                              'battery_2_hr':'sum','battery_4_hr':'sum'})).reset_index()\n",
    "\n",
    "    return site_interval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77386da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6= clean_data(site_interval_data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71e535b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test6=get_weekly_baseline(df6,0,16,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fd49510",
   "metadata": {},
   "outputs": [],
   "source": [
    "elrp6= get_revenue_values(test6)\n",
    "elrp6.to_csv('~/Downloads/ELRP_Generac8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "556e8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_weekly_baseline(x, day_of_bl, hour_start, hour_end):\n",
    "    x['dow']= x['date'].dt.dayofweek\n",
    "    x['week'] = x['date'] - pd.offsets.Week(weekday=6)\n",
    "\n",
    "#     weekday_series= x['dow']\n",
    "    ## Limit data set to the hours in question\n",
    "    \n",
    "    #NOTES: things to consider going forward:\n",
    "    # 1) rotating the days based on historic load consumption\n",
    "    # 2) rolling 45 days \n",
    "    moo_hours= x[(x['hour']>= hour_start) & (x['hour']<hour_end)]\n",
    "    \n",
    "# The below code takes: 1) Rolling 45 days 2) Find and average the five highest days IF that day \n",
    "# is the dow specified in the function \n",
    "    \n",
    "    \n",
    "    moo_hours['baseline_setting_base']=np.where(moo_hours['dow']==0, moo_hours['gross_load'], 0)\n",
    "    moo_hours['best_hour_kw'] = moo_hours.groupby(['hour'])['baseline_setting_base'].transform(lambda x:x.rolling(45).apply(lambda x: np.mean(sorted(x,reverse=True)[:5])))\n",
    "#     moo_hours['array'] = moo_hours.groupby(['hour'])['baseline_setting_base'].transform(lambda x:x.rolling(45).apply(lambda x: np.mean(sorted(x,reverse=True)[:5])))\n",
    "#     moo_hours['dummy'] = moo_hours.groupby('firm')['baseline_setting_base'].transform(lambda x: x.rolling(45).max().le(moo_hours['best_hour_kw']))\n",
    "\n",
    "    \n",
    "    z=moo_hours[moo_hours['dow']==0]\n",
    "    z=z[['week','hour','best_hour_kw']]\n",
    "    \n",
    "    #     x.set_index('hour')\n",
    "#     x['rolling_average']= x.groupby(['hour'])['gross_load'].transform(lambda x: np.mean(sorted(x,reverse=True)[:5]))\n",
    "    \n",
    "            \n",
    "    moo_hours = moo_hours.merge(right = z, on = ['week', 'hour'])\n",
    "       \n",
    "    moo_hours=moo_hours.drop(columns=['best_hour_kw_x'])\n",
    "    moo_hours=moo_hours.sort_values(['date','hour'])\n",
    "    moo_hours=moo_hours.drop_duplicates()\n",
    "#     x = x.drop(columns = ['solar_x','unit_x','genset_x','genset_y', 'date_y', 'gross_load_y','solar_y', 'storage_y', 'net load_x','unit_y', 'soc_y','dow_y'])\n",
    "#     x = x.rename(columns={'date_x': 'date','gross_load_x':'gross_load', 'storage_x':'storage', 'net load_y':'net_load', 'soc_x':'soc'})\n",
    "    ##redo bl calc for weekends \n",
    "\n",
    "    return moo_hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1717a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revenue_values(test):\n",
    "    test['month']= test['date'].dt.month\n",
    "    test['day']= test['date'].dt.day\n",
    "    test['year']= test['date'].dt.year\n",
    "    min_month= (test.groupby(['month','year']).agg({'day':'min',\n",
    "                                             'hour':'min',\n",
    "                             'baseline_setting_base': lambda x: (x > 0).mean()})).reset_index()\n",
    "\n",
    "    data = test.merge(min_month, on = ['year','month','day', 'hour'], how='left')\n",
    "    data= data.fillna(0)\n",
    "\n",
    "    data\n",
    "\n",
    "    _2022_cap_rate=({'month': [1,2,3,4,5,6,7,8,9,10,11,12], \n",
    "                     'value':[2970, 2963, 2999, 3037, 5036, 5368, 5472, 5474, 5479, 5298, 2778, 2684]})\n",
    "\n",
    "    idktest= pd.DataFrame.from_dict(_2022_cap_rate)\n",
    "    idktest\n",
    "    # idktest = idktest.rename(columns=('month', 'value'))\n",
    "    data2 = data.merge(idktest, on = ['month'], how='left')\n",
    "\n",
    "    data2['cap_rev']= data2['baseline_setting_base_y']* data2['value']\n",
    "    data2\n",
    "\n",
    "    energy_rev_data=pd.read_csv('/Users/suneetakartha/Downloads/energy_revenue_sizing_data.csv')\n",
    "    energy_rev_data =pd.melt(energy_rev_data, id_vars=['Month','Day'], value_vars=['17', '18','19','20'], ignore_index=False)\n",
    "    energy_rev_data.columns=['month', 'day', 'hour', 'energy_rev_val']\n",
    "    energy_rev_data['hour']=energy_rev_data['hour'].astype('int64')\n",
    "    final_rev= data2.merge(energy_rev_data, on = ['month','day','hour'], how='left')\n",
    "    final_rev['energy_rev']=np.where(final_rev['baseline_setting_base_x']>0, 0, final_rev['best_hour_kw_y']/1000* final_rev['energy_rev_val'])\n",
    "    final_rev=final_rev.drop(columns=['baseline_setting_base_y','value', 'energy_rev_val'])\n",
    "    return final_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f41e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_10in10_baseline_unadj(x): \n",
    "    #x must be a data frame with the following columns:\n",
    "    #datetime -- a date time column in pd, in utc\n",
    "    #load\n",
    "    #x = incremental.copy()\n",
    "#     x['date'] = x['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "#     weekday_series =  x['date'].dt.dayofweek\n",
    "#     x['is_weekday'] = (weekday_series!=6) & (weekday_series!=5)\n",
    "    x['time_id']=x['hour']\n",
    "    \n",
    "\n",
    "    date = x['date']\n",
    "    time_id = x['time_id']\n",
    "#     is_weekday = x['is_weekday']\n",
    "    load = x['gross_load']\n",
    "\n",
    "    dt = pd.DataFrame({'datetime':x['date'],\n",
    "                       'date':date, \n",
    "                       'time_id':time_id, \n",
    "#                        'is_weekday': is_weekday, \n",
    "                       'gross_load':load})\n",
    "    grouped = dt.groupby(['time_id'])\n",
    "    result = pd.DataFrame()\n",
    "    for name, group in grouped:\n",
    "        group = group.sort_values('date', ascending = True)\n",
    "        group['baseline_unadj'] = group['gross_load'].rolling(window=5, \n",
    "                                                       min_periods=10).mean().shift()\n",
    "        result = pd.concat([result,group])\n",
    "    x = x.merge(right = result, on = ['date', 'time_id', 'gross_load'])\n",
    "    x = x.drop(columns = ['date'])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecba5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.to_csv('~/Downloads/Resi_ELRP_GroupB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c7378b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testt=get_revenue_values(test2)\n",
    "testt.to_csv('~/Downloads/Resi_ELRP_GroupB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f19853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
